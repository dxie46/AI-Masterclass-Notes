{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfbbf2c",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "Hybrid models - combines different AI models together\n",
    "* CNN, MDN, GA, VAE, RNN, ES\n",
    "* Very powerful but computationally expensive to train\n",
    "\n",
    "**Useful resources:**\n",
    "<br>\n",
    "worldmodels.github.io\n",
    "<br>\n",
    "blog.otoro.net\n",
    "\n",
    "## Section 2\n",
    "\n",
    "**Neurons**\n",
    "<br>\n",
    "Recreation of a human neuron\n",
    "<br>\n",
    "Takes in input signals and has an output signal\n",
    "<br>\n",
    "Inputs are usually normalized\n",
    "<br>\n",
    "Weights - connectors between the inputs and neurons and is how the network learns\n",
    "<br>\n",
    "Sum of the weights multiplied by the input values are taken, then is passed through an activation function\n",
    "<br>\n",
    "**Activation Functions**\n",
    "<br>\n",
    "Threshold: values < 0 are set to 0; values >=0 are set to 1\n",
    "<br>\n",
    "Sigmoid: 1 / 1 + e^(-x)\n",
    "* S shaped curve bounded by 0 and 1\n",
    "<br>\n",
    "Rectifier: values < 0 are set to 0; values >=0 follow y=x line\n",
    "<br>\n",
    "Hyperbolic tangent: 1-e^(-2x) / 1+e^(-2x)\n",
    "* Similar to sigmoid but the S shaped curve is bounded between -1 and 1\n",
    "<br>\n",
    "\n",
    "**Neural Networks**\n",
    "<br>\n",
    "Hidden layers allow the network to pick out specific attributes\n",
    "<br>\n",
    "Two different approaches (providing the AI with labeled data vs. having the AI learn on its own)\n",
    "<br>\n",
    "(supervised vs. unsupervised learning)\n",
    "<br>\n",
    "Cost function tells us the error in our prediction (which we try to minimize)\n",
    "<br>\n",
    "Weights are updated according to the cost function\n",
    "<br>\n",
    "Process: inputs fed into network -> weights are applied -> output is generated -> output is compared to actual value -> if cost/error/loss is significant: -> weights are adjusted -> inputs refed into network -> process restarts again\n",
    "<br>\n",
    "Gradient descent: finding the smallest value in a given function (used to minimize cost function)\n",
    "<br>\n",
    "Stochastic gradient descent: finds the global minimum value (whereas gradient descent may error in that it finds the local minimum)\n",
    "* Weights are readjusted after each input whereas in normal gradient descent (batch gradient descent) all inputs are fed into the network and THEN the weights are readjusted\n",
    "* Is actually faster than batch gradient descent\n",
    "\n",
    "Backpropagation: readjusts all the weights at once in order to minimize the cost function and better approach desired behavior\n",
    "<br>\n",
    "Epoch: one complete run through of all input values through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5865212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
